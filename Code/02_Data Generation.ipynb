{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f21e817e-b3e2-4ee3-8f57-63b919929835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You may find this series of notebooks at https://github.com/databricks-industry-solutions/pos-dlt. For more information about this solution accelerator, visit https://www.databricks.com/solutions/accelerators/real-time-point-of-sale-analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a200912-23bc-4cd5-896c-be1da81c9c50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notebook yêu cầu tối thiểu 1 Worker node trong Databrick để chạy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94281181-76f2-4aed-9ea3-30dc6cdee313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notebook này có nhiệm vụ tạo ra một luồng dữ liệu liên quan đến tồn kho, xuất phát từ hai cửa hàng giả lập: một cửa hàng vật lý và một cửa hàng trực tuyến.\n",
    "\n",
    "Dữ liệu được truyền đến: Các dịch vụ ingest dữ liệu vào Iot Hub, như được đề cập trong notebook POS 01.\n",
    "Hai loại luồng dữ liệu chính:\n",
    "Sự kiện thay đổi tồn kho: Được ghi nhận từ hệ thống điểm bán hàng (Point-of-Sale System).\n",
    "Số lượng sản phẩm chụp nhanh (snapshot): Được xác định thông qua việc kiểm kê thủ công tại cửa hàng.\n",
    "</p>\n",
    "<img src='https://brysmiwasb.blob.core.windows.net/demos/images/pos_data_generation.png' width=400>\n",
    "\n",
    "- Khác biệt giữa hai luồng dữ liệu\n",
    "    - Tần suất cập nhật: Hai loại dữ liệu có tần suất sinh ra khác nhau.\n",
    "    - Khối lượng dữ liệu: Lượng dữ liệu của từng loại cũng khác nhau.\n",
    "    - Phương thức truyền tải: Vì các yếu tố trên, dữ liệu từ mỗi luồng được truyền đi bằng định dạng và cơ chế khác nhau.\n",
    "\n",
    "**IMPORTANT NOTE** The Azure IOT Hub is not reset between runs of this notebook.  As a result, it is possible that the messages delivered from prior runs could still be read by downstream streaming jobs.  To ensure a clean environment between runs, you may wish to first delete your Azure IOT Hub deployment and then recreate it.  This will require you to repeat the steps outlined in *POS 01* and update appropriate configuration values in that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "076c080a-e57b-4e89-80bf-7d914c7af276",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Required Libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-iot-device==2.7.1 --use-feature=2020-resolver\n",
    "%pip install azure-storage-blob==12.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38599e71-9f38-4297-ba5a-d57a6b7144ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"mode\", \"prod\")\n",
    "mode = dbutils.widgets.get(\"mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6e54ebe-e967-4fc3-81e5-9d27c9afeacb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Required Libraries"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "import datetime, time\n",
    "\n",
    "from azure.iot.device import IoTHubDeviceClient\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "454c893c-378d-42e8-b823-08fc113f4362",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Notebook Configuration"
    }
   },
   "outputs": [],
   "source": [
    "%run \"./01_Environment Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b25c54c-897b-4728-95b1-3783037b3cf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook is typically run to simulate a new stream of POS data. To ensure data from prior runs are not used in downstream calculations, you should reset the database and DLT engine environment between runs of this notebook:\n",
    "\n",
    "**NOTE** These actions are not typical of a real-world workflow but instead are here to ensure the proper calculation of values in a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "490d426e-3094-4232-94cf-5c2d8fd03e26",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reset the Target Database"
    }
   },
   "outputs": [],
   "source": [
    "_ = spark.sql(\"DROP DATABASE IF EXISTS {0} CASCADE\".format(config['database']))\n",
    "_ = spark.sql(\"CREATE DATABASE IF NOT EXISTS {0}\".format(config['database']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beeb27fa-e560-471d-b5e9-1a766cfe2b68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**NOTE** This next step should be run before any DLT jobs are launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb9d38e5-9612-458f-b2b5-a566c35fd6f1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reset the DLT Environment"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(config['dlt_pipeline'],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6d343f8-4141-4afb-829e-ca8e6d0657cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Assemble Inventory Change Records\n",
    "\n",
    "Mục đích: Tạo dữ liệu ghi nhận các sự kiện làm thay đổi tồn kho tại cửa hàng.\n",
    "\n",
    "Các loại sự kiện:\n",
    "- Giao dịch bán hàng: Các mặt hàng được bán trực tiếp.\n",
    "- Ghi nhận tổn thất: Hàng hóa bị mất, hư hỏng hoặc bị trộm.\n",
    "- Sự kiện bổ sung hàng: Khi hàng hóa được nhập thêm vào kho.\n",
    "- BOPIS (Buy-Online, Pickup In-Store): Đơn hàng trực tuyến nhưng được hoàn tất tại cửa hàng vật lý.\n",
    "- Luồng dữ liệu sự kiện thay đổi tồn kho\n",
    "\n",
    "-> Mặc dù mỗi loại sự kiện có các thuộc tính riêng biệt, tất cả đều được gom chung vào một luồng duy nhất.\n",
    "\n",
    "Phân biệt loại sự kiện: Các sự kiện được nhận diện thông qua mã định danh (change type identifier).\n",
    "Đặc điểm của từng sự kiện\n",
    "\n",
    "- Một sự kiện có thể liên quan đến nhiều sản phẩm (items):\n",
    "    - Dữ liệu được nhóm lại dựa trên Transaction ID (ID giao dịch), là mã duy nhất đại diện cho từng sự kiện.\n",
    "    - Nhờ cách tổ chức này, dữ liệu về nhiều sản phẩm trong cùng một giao dịch hoặc sự kiện được truyền tải một cách hiệu quả.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f72cc450-cae3-4e62-84ff-8d08714f2003",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Combine & Reformat Inventory Change Records"
    }
   },
   "outputs": [],
   "source": [
    "# format of inventory change records\n",
    "inventory_change_schema = StructType([\n",
    "  StructField('trans_id', StringType()),  # transaction event ID\n",
    "  StructField('item_id', IntegerType()),  \n",
    "  StructField('store_id', IntegerType()),\n",
    "  StructField('date_time', TimestampType()),\n",
    "  StructField('quantity', IntegerType()),\n",
    "  StructField('change_type_id', IntegerType())\n",
    "  ])\n",
    "\n",
    "# inventory change record data files (one from each store)\n",
    "inventory_change_files = [\n",
    "  config['inventory_change_store001_filename'],\n",
    "  config['inventory_change_online_filename']\n",
    "  ]\n",
    "\n",
    "# read inventory change records and group items associated with each transaction so that one output record represents one complete transaction\n",
    "inventory_change = (\n",
    "  spark\n",
    "    .read\n",
    "    .csv(\n",
    "      inventory_change_files, \n",
    "      header=True, \n",
    "      schema=inventory_change_schema, \n",
    "      timestampFormat='yyyy-MM-dd HH:mm:ss'\n",
    "      )\n",
    "    .withColumn('trans_id', f.expr('substring(trans_id, 2, length(trans_id)-2)')) # remove surrounding curly braces from trans id\n",
    "    .withColumn('item', f.struct('item_id', 'quantity')) # combine items and quantities into structures from which we can build a list\n",
    "    .groupBy('date_time','trans_id')\n",
    "      .agg(\n",
    "        f.first('store_id').alias('store_id'),\n",
    "        f.first('change_type_id').alias('change_type_id'),\n",
    "        f.collect_list('item').alias('items')  # organize item info as a list\n",
    "        )\n",
    "    .orderBy('date_time','trans_id')\n",
    "    .toJSON()\n",
    "    .collect()\n",
    "  )\n",
    "\n",
    "# print a single transaction record to illustrate data structure\n",
    "eval(inventory_change[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0b01cd3-8740-46a0-954e-210eaa7a5f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Assemble Inventory Snapshots\n",
    "\n",
    "- Tạo dữ liệu Inventory Snapshots - bản ghi số lượng hàng hóa tồn kho thực tế tại thời điểm kiểm kê.\n",
    "- Phản ánh chính xác trạng thái hàng tồn kho, khắc phục sai lệch do mất mát, lỗi nhập liệu, hoặc các sự cố khác.\n",
    "- Kiểm kê toàn bộ sản phẩm tại cửa hàng mỗi 5 ngày, giúp nhanh chóng minh họa logic xử lý streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f06ab2a5-9f20-4662-8599-fb71de28b06b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Access Inventory Snapshots"
    }
   },
   "outputs": [],
   "source": [
    "# format of inventory snapshot records\n",
    "inventory_snapshot_schema = StructType([\n",
    "  StructField('item_id', IntegerType()),\n",
    "  StructField('employee_id', IntegerType()),\n",
    "  StructField('store_id', IntegerType()),\n",
    "  StructField('date_time', TimestampType()),\n",
    "  StructField('quantity', IntegerType())\n",
    "  ])\n",
    "\n",
    "# inventory snapshot files\n",
    "inventory_snapshot_files = [ \n",
    "  config['inventory_snapshot_store001_filename'],\n",
    "  config['inventory_snapshot_online_filename']\n",
    "  ]\n",
    "\n",
    "# read inventory snapshot data\n",
    "inventory_snapshots = (\n",
    "  spark\n",
    "    .read\n",
    "    .csv(\n",
    "      inventory_snapshot_files, \n",
    "      header=True, \n",
    "      timestampFormat='yyyy-MM-dd HH:mm:ss', \n",
    "      schema=inventory_snapshot_schema\n",
    "      )\n",
    "  )\n",
    "\n",
    "display(inventory_snapshots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "192c36ec-32b2-4139-a35b-1618763f3729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To coordinate the transmission of change event data with periodic snapshots, the unique dates and times for which snapshots were taken within a given store location are extracted to a list.  This list will be used in the section of code that follows:\n",
    "\n",
    "**NOTE** It is critical for the logic below that this list of dates is sorted in chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ef9c96c-14ab-47d1-aa28-0ca766950f24",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Assemble Set of Snapshot DateTimes by Store"
    }
   },
   "outputs": [],
   "source": [
    "# get date_time of each inventory snapshot by store\n",
    "inventory_snapshot_times = (\n",
    "  inventory_snapshots\n",
    "    .select('date_time','store_id')\n",
    "    .distinct()\n",
    "    .orderBy('date_time')  # sorting of list is essential for logic below\n",
    "  ).collect()\n",
    "\n",
    "# display snapshot times\n",
    "inventory_snapshot_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2360552-70bc-4f8f-aed1-f431613f8453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Transmit Store Data to the Cloud\n",
    "\n",
    "- Tiếp theo chúng ta sẽ gửi những sự kiện ở dạng JSON tới Azure IOT Hub. Bắt những thời gian thay đổi giữa các giao dịch, chúng ta sẽ delay bằng cách tính toán độ trễ giữa các giao dịch bằng cách đo thời gian giữa giao dịch hiện tại và giao dịch trước đó. Số giây trễ sẽ được tính toán và điều chỉnh theo biến event_speed_factor, cho phép bạn tùy chỉnh tốc độ phát lại dữ liệu (tăng hoặc giảm).\n",
    "\n",
    "**NOTE** Azure IoT Hub có giới hạn về số lượng sự kiện có thể được truyền mỗi giây. Nếu giới hạn này bị vượt qua, bạn có thể gặp phải lỗi 429 từ client của IoT Hub. Điều này có thể ảnh hưởng đến quá trình truyền tải dữ liệu và có thể làm chậm hệ thống. Để biết thêm chi tiết về các giới hạn và cơ chế điều tiết này, bạn có thể [tham khảo](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-quotas-throttling).\n",
    "\n",
    "Trong quá trình truyền dữ liệu, hệ thống sẽ kiểm tra và xác định xem có cần tạo và gửi các file snapshot mới vào tài khoản Azure Storage hay không. Để đảm bảo các dữ liệu snapshot được nhận đúng theo thứ tự, mọi file snapshot cũ sẽ bị xóa trước khi bắt đầu quá trình truyền tải dữ liệu mới. Điều này đảm bảo rằng không có sự cố về trùng lặp dữ liệu hoặc mất đồng bộ khi xử lý các sự kiện và snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47887c0e-b8ef-40d1-964c-6be227b3fef6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delete Any Old Snapshot Files"
    }
   },
   "outputs": [],
   "source": [
    "# connect to container holding old snapshots\n",
    "blob_service_client = BlobServiceClient.from_connection_string(config['storage_connection_string'])\n",
    "container_client = blob_service_client.get_container_client(container=config['storage_container_name'])\n",
    "\n",
    "# for each blob in specified \"path\"\n",
    "for blob in container_client.list_blobs(name_starts_with=config['inventory_snapshot_path'].replace(config['dbfs_mount_name'],'')[1:]):\n",
    "  blob_client = container_client.get_blob_client(blob)\n",
    "  blob_client.delete_blob()\n",
    "\n",
    "# close clients\n",
    "container_client.close()\n",
    "blob_service_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e207c4b-5d41-4a1f-aba8-e47aefc26620",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Connect to IOT Hub"
    }
   },
   "outputs": [],
   "source": [
    "# make sure to disconnect if this is a re-run of the notebook\n",
    "if 'client' in locals():\n",
    "  try:\n",
    "    client.disconnect()\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "# connect to iot hub\n",
    "client = IoTHubDeviceClient.create_from_connection_string( config['iot_device_connection_string'] )\n",
    "client.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaac48ae-a000-413c-82ea-c668607202d1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Send Transactions"
    }
   },
   "outputs": [],
   "source": [
    "if mode != \"prod\":\n",
    "  inventory_change = inventory_change[:100] # limit the number of transactions here to shorten execution duration; this notebook is engineered to run for approx. 3 days without this limit\n",
    "event_speed_factor = 10 # Send records to iot hub at <event_speed_factor> X real-time speed\n",
    "max_msg_size = 256 * 1024 # event message to iot hub cannot exceed 256KB\n",
    "last_dt = None\n",
    "\n",
    "for event in inventory_change:\n",
    "  # extract datetime from transaction document\n",
    "  d = eval(event) # evaluate json as a dictionary\n",
    "  dt = datetime.datetime.strptime( d['date_time'], '%Y-%m-%dT%H:%M:%S.000Z')\n",
    "  \n",
    "  # inventory snapshot transmission\n",
    "  # -----------------------------------------------------------------------\n",
    "  snapshot_start = time.time()\n",
    "  \n",
    "  inventory_snapshot_times_for_loop = inventory_snapshot_times # copy snapshot times list as this may be modified in loop\n",
    "  for snapshot_dt, store_id in inventory_snapshot_times_for_loop: # for each snapshot\n",
    "    \n",
    "    # if event date time is before next snapshot date time\n",
    "    if dt < snapshot_dt: # (snapshot times are ordered by date)\n",
    "      break              #   nothing to transmit\n",
    "      \n",
    "    else: # event date time exceeds a snapshot datetime\n",
    "      \n",
    "      # extract snapshot data for this dt\n",
    "      snapshot_pd = (\n",
    "        inventory_snapshots\n",
    "          .filter(f.expr(\"store_id={0} AND date_time='{1}'\".format(store_id, snapshot_dt)))\n",
    "          .withColumn('date_time', f.expr(\"date_format(date_time, 'yyyy-MM-dd HH:mm:ss')\")) # force timestamp conversion to include \n",
    "          .toPandas()  \n",
    "           )\n",
    "        \n",
    "      # transmit to storage blob as csv\n",
    "      blob_service_client = BlobServiceClient.from_connection_string(config['storage_connection_string'])\n",
    "      blob_client = blob_service_client.get_blob_client(\n",
    "        container=config['storage_container_name'], \n",
    "        blob=(config['inventory_snapshot_path'].replace(config['dbfs_mount_name'],'')[1:]+\n",
    "              'inventory_snapshot_{0}_{1}'.format(store_id,snapshot_dt.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "        )\n",
    "      blob_client.upload_blob(str(snapshot_pd.to_csv()), overwrite=True)\n",
    "      blob_client.close()\n",
    "      \n",
    "      # remove snapshot date from inventory_snapshot_times\n",
    "      inventory_snapshot_times.pop(0)\n",
    "      print('Loaded inventory snapshot for {0}'.format(snapshot_dt.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "      \n",
    "  snapshot_seconds = time.time() - snapshot_start\n",
    "  # -----------------------------------------------------------------------\n",
    "  \n",
    "  # inventory change event transmission\n",
    "  # -----------------------------------------------------------------------\n",
    "  # calculate delay (in seconds) between this event and prior event (account for snapshot)\n",
    "  if last_dt is None: last_dt = dt\n",
    "  delay = (dt - last_dt).seconds - snapshot_seconds\n",
    "  delay = int(delay/event_speed_factor) # adjust delay by event speed factor\n",
    "  if delay < 0: delay = 0\n",
    "  \n",
    "  # sleep for delay duration\n",
    "  #print('Sleep for {0} seconds'.format(delay))\n",
    "  #time.sleep(delay)\n",
    "  \n",
    "  # send items individually if json document too large\n",
    "  # change log feb 28 2022 - added `temp = [item]` to convert dictionary to list.\n",
    "  if len(event) > max_msg_size:\n",
    "    items = d.pop('items') # retrieve items collection\n",
    "    for i, item in enumerate(items): # for each item\n",
    "      temp = [item]\n",
    "      d['items'] = temp   # add a one-item items-collection\n",
    "      client.send_message(str(d)) # send message\n",
    "\n",
    "      if (i+1)%25==0: # pause transmission every Xth item to avoid overwhelming IOT hub\n",
    "        time.sleep(1)\n",
    "  else:  # send whole transaction document\n",
    "    client.send_message(event)\n",
    "    \n",
    "  # -----------------------------------------------------------------------\n",
    "  \n",
    "  # set last_dt for next cycle\n",
    "  last_dt = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ce80dba-c745-45ae-bd9c-d9bc72a8e3fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Disconnect from IOT Hub"
    }
   },
   "outputs": [],
   "source": [
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fbca624-1a0b-4bcd-afb4-0072f97c5f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2022 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the [Databricks License](https://databricks.com/db-license-source).  All included or referenced third party libraries are subject to the licenses set forth below.\n",
    "\n",
    "| library                                | description             | license    | source                                              |\n",
    "|----------------------------------------|-------------------------|------------|-----------------------------------------------------|\n",
    "| azure-iot-device                                     | Microsoft Azure IoT Device Library | MIT    | https://pypi.org/project/azure-iot-device/                       |\n",
    "| azure-storage-blob                                | Microsoft Azure Blob Storage Client Library for Python| MIT        | https://pypi.org/project/azure-storage-blob/      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51889827-a180-4650-8640-33113d3030f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_Data Generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
